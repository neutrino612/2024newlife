{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载飞桨和相关类库\n",
    "import paddle\n",
    "from paddle.nn import Linear\n",
    "import paddle.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from paddle.vision.transforms import Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置数据读取器，API自动读取MNIST数据训练集\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义mnist数据识别网络结构，同房价预测网络\n",
    "class MNIST(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(MNIST, self).__init__()\n",
    "        \n",
    "        # 定义一层全连接层，输出维度是1\n",
    "        self.fc = paddle.nn.Linear(in_features=784, out_features=1)\n",
    "        \n",
    "    # 定义网络结构的前向计算过程\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.fc(inputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像归一化函数，将数据范围为[0, 255]的图像归一化到[0, 1]\n",
    "def norm_img(img):\n",
    "    # 验证传入数据格式是否正确，img的shape为[batch_size, 28, 28]\n",
    "    assert len(img.shape) == 3\n",
    "    batch_size, img_h, img_w = img.shape[0], img.shape[1], img.shape[2]\n",
    "    # 归一化图像数据\n",
    "    img = img / 255\n",
    "    # 将图像形式reshape为[batch_size, 784]\n",
    "    img = paddle.reshape(img, [batch_size, img_h*img_w])\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_id: 0, batch_id: 0, loss is: 20.11361312866211\n",
      "epoch_id: 0, batch_id: 1000, loss is: 3.081111431121826\n",
      "epoch_id: 0, batch_id: 2000, loss is: 3.2629332542419434\n",
      "epoch_id: 0, batch_id: 3000, loss is: 4.0055012702941895\n",
      "epoch_id: 1, batch_id: 0, loss is: 3.611865997314453\n",
      "epoch_id: 1, batch_id: 1000, loss is: 2.583967447280884\n",
      "epoch_id: 1, batch_id: 2000, loss is: 2.9955530166625977\n",
      "epoch_id: 1, batch_id: 3000, loss is: 4.041898727416992\n",
      "epoch_id: 2, batch_id: 0, loss is: 2.287470817565918\n",
      "epoch_id: 2, batch_id: 1000, loss is: 3.9004974365234375\n",
      "epoch_id: 2, batch_id: 2000, loss is: 2.0123229026794434\n",
      "epoch_id: 2, batch_id: 3000, loss is: 2.329176425933838\n",
      "epoch_id: 3, batch_id: 0, loss is: 1.519679069519043\n",
      "epoch_id: 3, batch_id: 1000, loss is: 4.726850986480713\n",
      "epoch_id: 3, batch_id: 2000, loss is: 2.2296509742736816\n",
      "epoch_id: 3, batch_id: 3000, loss is: 3.574422836303711\n",
      "epoch_id: 4, batch_id: 0, loss is: 4.445947170257568\n",
      "epoch_id: 4, batch_id: 1000, loss is: 2.2102999687194824\n",
      "epoch_id: 4, batch_id: 2000, loss is: 1.9571094512939453\n",
      "epoch_id: 4, batch_id: 3000, loss is: 2.4345054626464844\n",
      "epoch_id: 5, batch_id: 0, loss is: 1.8925249576568604\n",
      "epoch_id: 5, batch_id: 1000, loss is: 1.7898060083389282\n",
      "epoch_id: 5, batch_id: 2000, loss is: 3.295726776123047\n",
      "epoch_id: 5, batch_id: 3000, loss is: 0.4782465100288391\n",
      "epoch_id: 6, batch_id: 0, loss is: 5.876949310302734\n",
      "epoch_id: 6, batch_id: 1000, loss is: 3.0020644664764404\n",
      "epoch_id: 6, batch_id: 2000, loss is: 0.9274085760116577\n",
      "epoch_id: 6, batch_id: 3000, loss is: 2.3440089225769043\n",
      "epoch_id: 7, batch_id: 0, loss is: 3.3174853324890137\n",
      "epoch_id: 7, batch_id: 1000, loss is: 2.436628818511963\n",
      "epoch_id: 7, batch_id: 2000, loss is: 2.3517255783081055\n",
      "epoch_id: 7, batch_id: 3000, loss is: 2.0888795852661133\n",
      "epoch_id: 8, batch_id: 0, loss is: 3.2358617782592773\n",
      "epoch_id: 8, batch_id: 1000, loss is: 5.5237956047058105\n",
      "epoch_id: 8, batch_id: 2000, loss is: 1.9423216581344604\n",
      "epoch_id: 8, batch_id: 3000, loss is: 2.6557295322418213\n",
      "epoch_id: 9, batch_id: 0, loss is: 3.918632984161377\n",
      "epoch_id: 9, batch_id: 1000, loss is: 1.1386653184890747\n",
      "epoch_id: 9, batch_id: 2000, loss is: 2.9767005443573\n",
      "epoch_id: 9, batch_id: 3000, loss is: 2.4121387004852295\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "# 确保从paddle.vision.datasets.MNIST中加载的图像数据是np.ndarray类型\n",
    "paddle.vision.set_image_backend('cv2')\n",
    "\n",
    "# 声明网络结构\n",
    "model = MNIST()\n",
    "\n",
    "def train(model):\n",
    "    # 启动训练模式\n",
    "    model.train()\n",
    "    # 加载训练集 batch_size 设为 16\n",
    "    train_loader = paddle.io.DataLoader(paddle.vision.datasets.MNIST(mode='train'), \n",
    "                                        batch_size=16, \n",
    "                                        shuffle=True)\n",
    "    # 定义优化器，使用随机梯度下降SGD优化器，学习率设置为0.001\n",
    "    opt = paddle.optimizer.SGD(learning_rate=0.001, parameters=model.parameters())\n",
    "    EPOCH_NUM = 10\n",
    "    for epoch in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            images = norm_img(data[0]).astype('float32')\n",
    "            labels = data[1].astype('float32')\n",
    "            \n",
    "            #前向计算的过程\n",
    "            predicts = model(images)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = F.square_error_cost(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "            \n",
    "            #每训练了1000批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 1000 == 0:\n",
    "                print(\"epoch_id: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, avg_loss.numpy()))\n",
    "            \n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "            \n",
    "train(model)\n",
    "paddle.save(model.state_dict(), './mnist.pdparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\paddle_24\\lib\\site-packages\\paddle\\nn\\layer\\layers.py:2084: UserWarning: Skip loading for weight. weight is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n",
      "d:\\anaconda3\\envs\\paddle_24\\lib\\site-packages\\paddle\\nn\\layer\\layers.py:2084: UserWarning: Skip loading for bias. bias is not found in the provided dict.\n",
      "  warnings.warn(f\"Skip loading for {key}. \" + str(err))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true label: 7, pred label: Tensor(shape=[], dtype=int64, place=Place(cpu), stop_gradient=True,\n",
      "       6296)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28e0dea1fd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "layer = paddle.nn.Conv2D(1, 10, 3)\n",
    "layer.set_state_dict(paddle.load('./mnist.pdparams'))\n",
    "transform = Normalize(mean=[127.5], std=[127.5], data_format=\"CHW\")\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode=\"test\",transform=transform)\n",
    "img, label = test_dataset[0]\n",
    "# 将图片shape从1*28*28变为1*1*28*28，增加一个batch维度，以匹配模型输入格式要求\n",
    "img_batch = np.expand_dims(img.astype(\"float32\"), axis=0)\n",
    "# 执行推理并打印结果，此处predict_batch返回的是一个list，取出其中数据获得预测结果\n",
    "out = layer.forward(paddle.to_tensor(img_batch))\n",
    "pred_label = out.argmax()\n",
    "print(\"true label: {}, pred label: {}\".format(label[0], pred_label))\n",
    "# 可视化图片\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(img[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
