{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入飞桨的库\n",
    "同步数据读取：数据读取与模型训练串行。当模型需要数据时，才运行数据读取函数获得当前批次的数据。在读取数据期间，模型一直等待数据读取结束才进行训练，数据读取速度相对较慢。\n",
    "异步数据读取：数据读取和模型训练并行。读取到的数据不断的放入缓存区，无需等待模型训练就可以启动下一轮数据读取。当模型训练完一个批次后，不用等待数据读取过程，直接从缓存区获得下一批次数据进行训练，从而加快了数据读取速度。\n",
    "异步队列：数据读取和模型训练交互的仓库，二者均可以从仓库中读取数据，它的存在使得两者的工作节奏可以解耦。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import json\n",
    "import gzip\n",
    "import numpy as np\n",
    "from paddle.nn import Linear\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "# 创建一个类MnistDataset，继承paddle.io.Dataset 这个类\n",
    "# MnistDataset的作用和上面load_data()函数的作用相同，均是构建一个迭代器\n",
    "class MnistDataset(paddle.io.Dataset):\n",
    "    def __init__(self, mode):\n",
    "        datafile = 'mnist.json.gz'\n",
    "        data = json.load(gzip.open(datafile))\n",
    "        # 读取到的数据区分训练集，验证集，测试集\n",
    "        train_set, val_set, eval_set = data\n",
    "        if mode=='train':\n",
    "            # 获得训练数据集\n",
    "            imgs, labels = train_set[0], train_set[1]\n",
    "        elif mode=='valid':\n",
    "            # 获得验证数据集\n",
    "            imgs, labels = val_set[0], val_set[1]\n",
    "        elif mode=='eval':\n",
    "            # 获得测试数据集\n",
    "            imgs, labels = eval_set[0], eval_set[1]\n",
    "        else:\n",
    "            raise Exception(\"mode can only be one of ['train', 'valid', 'eval']\")\n",
    "        \n",
    "        # 校验数据\n",
    "        imgs_length = len(imgs)\n",
    "        assert len(imgs) == len(labels), \\\n",
    "            \"length of train_imgs({}) should be the same as train_labels({})\".format(len(imgs), len(labels))\n",
    "        \n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = np.array(self.imgs[idx]).astype('float32')\n",
    "        label = np.array(self.labels[idx]).astype('float32')\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [100, 784] [100]\n",
      "1 [100, 784] [100]\n",
      "2 [100, 784] [100]\n"
     ]
    }
   ],
   "source": [
    "# 声明数据加载函数，使用MnistDataset数据集\n",
    "train_dataset = MnistDataset(mode='train')\n",
    "# 使用paddle.io.DataLoader 定义DataLoader对象用于加载Python生成器产生的数据，\n",
    "# DataLoader 返回的是一个批次数据迭代器，并且是异步的；\n",
    "data_loader = paddle.io.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "# 迭代的读取数据并打印数据的形状\n",
    "for i, data in enumerate(data_loader()):\n",
    "    images, labels = data\n",
    "    print(i, images.shape, labels.shape)\n",
    "    if i>=2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss is: 22.108009338378906\n",
      "epoch: 0, batch: 200, loss is: 8.29177188873291\n",
      "epoch: 0, batch: 400, loss is: 7.531145095825195\n",
      "epoch: 1, batch: 0, loss is: 8.61501407623291\n",
      "epoch: 1, batch: 200, loss is: 9.100568771362305\n",
      "epoch: 1, batch: 400, loss is: 8.53562068939209\n",
      "epoch: 2, batch: 0, loss is: 8.085770606994629\n",
      "epoch: 2, batch: 200, loss is: 8.245512962341309\n",
      "epoch: 2, batch: 400, loss is: 7.882917404174805\n",
      "epoch: 3, batch: 0, loss is: 7.482028961181641\n",
      "epoch: 3, batch: 200, loss is: 9.862553596496582\n",
      "epoch: 3, batch: 400, loss is: 10.190206527709961\n",
      "epoch: 4, batch: 0, loss is: 7.704078197479248\n",
      "epoch: 4, batch: 200, loss is: 7.877786159515381\n",
      "epoch: 4, batch: 400, loss is: 9.184771537780762\n",
      "epoch: 5, batch: 0, loss is: 8.642525672912598\n",
      "epoch: 5, batch: 200, loss is: 8.431878089904785\n",
      "epoch: 5, batch: 400, loss is: 7.731142044067383\n",
      "epoch: 6, batch: 0, loss is: 7.777571678161621\n",
      "epoch: 6, batch: 200, loss is: 9.009143829345703\n",
      "epoch: 6, batch: 400, loss is: 9.263579368591309\n",
      "epoch: 7, batch: 0, loss is: 8.702855110168457\n",
      "epoch: 7, batch: 200, loss is: 8.290546417236328\n",
      "epoch: 7, batch: 400, loss is: 8.928837776184082\n",
      "epoch: 8, batch: 0, loss is: 8.764410018920898\n",
      "epoch: 8, batch: 200, loss is: 8.777275085449219\n",
      "epoch: 8, batch: 400, loss is: 9.618757247924805\n",
      "epoch: 9, batch: 0, loss is: 8.282417297363281\n",
      "epoch: 9, batch: 200, loss is: 8.428976058959961\n",
      "epoch: 9, batch: 400, loss is: 8.423885345458984\n"
     ]
    }
   ],
   "source": [
    "#数据处理部分之后的代码，数据读取的部分调用Load_data函数\n",
    "#定义网络结构，同上一节所使用的网络结构\n",
    "class MNIST(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(MNIST, self).__init__()\n",
    "        # 定义一层全连接层，输出维度是1\n",
    "        self.fc = paddle.nn.Linear(in_features=784, out_features=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.fc(inputs)\n",
    "        return outputs\n",
    "# 异步数据读取并训练的完整案例代码如下所示\n",
    "def train(model):\n",
    "    model = MNIST()\n",
    "    model.train()\n",
    "    opt = paddle.optimizer.SGD(learning_rate=0.001, parameters=model.parameters())\n",
    "    EPOCH_NUM = 10\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(data_loader()):\n",
    "            images, labels = data\n",
    "            images = paddle.to_tensor(images)\n",
    "            labels = paddle.to_tensor(labels).astype('float32')\n",
    "            \n",
    "            #前向计算的过程  \n",
    "            predicts = model(images)\n",
    "\n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = F.square_error_cost(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)       \n",
    "            \n",
    "            #每训练了200批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch_id, batch_id, avg_loss.numpy()))\n",
    "            \n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "    #保存模型参数\n",
    "    paddle.save(model.state_dict(), 'mnist')\n",
    "\n",
    "#创建模型\n",
    "model = MNIST()\n",
    "#启动训练过程\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从异步数据读取的训练结果来看，损失函数下降与同步数据读取训练结果一致。注意，异步读取数据只在数据量规模巨大时会带来显著的性能提升，对于多数场景采用同步数据读取的方式已经足够。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle_24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
